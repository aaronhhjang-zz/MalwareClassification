import warnings

import pandas as pd
import os
import glob
import logging

import scipy
from sklearn.preprocessing import LabelEncoder
from sklearn import tree
import numpy as np
import dataPreprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC, SVR
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV

path_to_json = r".\simplifiedReports\\"

# Inputs & Target dataframes persisted in respective pkl files.
# Delete the files if data changes and preprocessing should be rerun.
inputs_pkl_filename = "inputs-NNNS.pkl"
target_pkl_filenmae = "target-NNNS.pkl"

# Configure logging
logging.basicConfig(filename="results-NNNS.log",
                            filemode='a',
                            format='%(asctime)s %(levelname)s %(message)s',
                            datefmt="%Y-%m-%d %H:%M:%S",
                            level=logging.DEBUG)
logging.info("==================================================================") # Separation for each line

def get_score(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train) 
<<<<<<< Updated upstream:MalwareClassifiers-noName-noScore.py
    score = model.score(X_test, y_test)
    logging.info("SCORE OF " + str(model) + ": " + str(score))
=======
    print("---------------SCORE OF " + str(model))
    print(model.score(X_test, y_test))
    #return model.score(X_test, y_test)
    prediction = model.predict_proba(X_test)
    print(prediction)
>>>>>>> Stashed changes:MalwareClassifier-DecisionTree.py
    if(hasattr(model, "best_params_")):
        logging.debug("=======(values from best_params and best_score)=======")
        logging.info("Tuned Params {}".format(model.best_params_))
        logging.info("Best score is {}".format(model.best_score_))
    return score

def preprocess_data():
    # Read all json files into pandas dataframe
    json_pattern = os.path.join(path_to_json,'*.json')
    file_list = glob.glob(json_pattern)
    dfs = [] # an empty list to store the data frames
    for file in file_list:
        data = pd.read_json(file, lines=True) # read data frame from json file
        dfs.append(data) # append the data frame to the list
    df = pd.concat(dfs, ignore_index=True) # concatenate all the data frames in the list.

    #making "inputs" dataframe
    #split data into inputs and target (X and Y)
    inputs = df.drop(['name', 'score','signatures','family'], axis='columns')
    #inputs = inputs.drop('family', axis='columns')
    target = df['family']

    index = 0
    for feature in dataPreprocessing.FEATURES:
        inputs[feature] = dataPreprocessing.transposedFeatureMatrix[index]
        index += 1

    #shuffles dataframe (to randomize data order)
    inputs.sample(frac=1).reset_index(drop=True)
    return inputs, target

try:
    inputs = pd.read_pickle(inputs_pkl_filename)
    target = pd.read_pickle(target_pkl_filenmae)
except:
    print('Data not found. Need to run preprocess input and target...')
    inputs, target = preprocess_data()
    inputs.to_pickle(inputs_pkl_filename)
    target.to_pickle(target_pkl_filenmae)


X_train, X_test, y_train, y_test = train_test_split(inputs, target,test_size=0.2, random_state=0)

#========Decision tree=========
tree_vanilla = tree.DecisionTreeClassifier()
params_tree = {"max_depth": [3,4,5,6,7],   #list of parameter combinations to try
          "min_samples_leaf" : [2,3,4,5,6,7,8],
          "criterion": ["entropy"]
          }
warnings.filterwarnings("ignore")
tree_cv = RandomizedSearchCV(tree_vanilla, params_tree, cv=5, n_iter=8)



#=======SVM==============
svm_vanilla = SVC()
#svm_vanilla2 = SVR(cache_size=7000)
# params_svm = {'C': [1,5,10], 'gamma': ['auto'],
#   'kernel': ['rbf', 'linear'], 'class_weight':['balanced', None]}
# # warnings.filterwarnings("ignore")
# svmModel = RandomizedSearchCV(SVC(), params_svm,cv=5, n_iter=3)

#=========random forest============
randForest_vanilla = RandomForestClassifier()

# # ============Random Forest Hyperparameters============
# # Number of trees in random forest
# n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]
# # Number of features to consider at every split
# max_features = ['auto', 'sqrt']
# # Maximum number of levels in tree
# max_depth = [2,4]
# # Minimum number of samples required to split a node
# min_samples_split = [2, 5]
# # Minimum number of samples required at each leaf node
# min_samples_leaf = [1, 2]
# # Method of selecting samples for training each tree
# bootstrap = [True, False]
# # Create the param grid
# param_grid = {'n_estimators': n_estimators,
#                'max_features': max_features,
#                'max_depth': max_depth,
#                'min_samples_split': min_samples_split,
#                'min_samples_leaf': min_samples_leaf,
#                'bootstrap': bootstrap}
# rf_Model = RandomForestClassifier()

# rf_Grid = GridSearchCV(estimator = rf_Model, param_grid = param_grid, cv = 3, verbose=2, n_jobs = 4)
# rf_Grid.fit(X_train, y_train)

# logging.info(rf_Grid.best_params_)

# # Check accuracy
# logging.info (f'Train Accuracy - : {rf_Grid.score(X_train,y_train):.3f}')
# logging.info (f'Test Accuracy - : {rf_Grid.score(X_test,y_test):.3f}')
# ============END OF Random Forest Hyperparameters============

#========Gradient Boost==============
gradBoost_vanilla = GradientBoostingClassifier()
<<<<<<< Updated upstream:MalwareClassifiers-noName-noScore.py
params_GB = {'learning_rate':[0.15,0.01, 1], 'n_estimators':[3,10,20]}
=======
params_GB = {'learning_rate':[0.15], 'n_estimators':[10]}
gb_tuned = GridSearchCV(gradBoost_vanilla, params_GB)

>>>>>>> Stashed changes:MalwareClassifier-DecisionTree.py

get_score(tree_vanilla, X_train, X_test, y_train, y_test)
get_score(tree_cv, X_train, X_test, y_train, y_test)
get_score(svm_vanilla, X_train, X_test, y_train, y_test)
#get_score(svm_vanilla2, X_train, X_test, y_train, y_test)
get_score(randForest_vanilla, X_train, X_test, y_train, y_test)
